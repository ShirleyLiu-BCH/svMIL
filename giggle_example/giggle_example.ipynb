{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from giggle import Giggle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from __future__ import division\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bed_files/genes.bed.gz',\n",
       " u'bed_files/tads.bed.gz',\n",
       " u'bed_files/wgEncodeBroadHmmGm12878HMM.bed.gz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading or creating the index\n",
    "index = Giggle.create(\"index\", \"bed_files/*.bed.gz\") #or index = Giggle(\"index\") \n",
    "index.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read the true negative and true positives sets (data/TN_127.txt and data/TP_127.txt). Returns them as numpy arrays. \n",
    "def read_sv_data(data, pathogenic):\n",
    "    SVdata = []\n",
    "\n",
    "    with open(data) as f:\n",
    "        linecount = 0\n",
    "        #skipping the header\n",
    "        for line in f:\n",
    "\n",
    "            if linecount < 1:                                       \n",
    "                linecount += 1\n",
    "                continue\n",
    "\n",
    "            line = line.strip()\n",
    "            splitline = line.split(\"\\t\")\n",
    "\n",
    "            if pathogenic == 0:                                    \n",
    "                #Get the chromsome, start and end positions and sv type\n",
    "                chr1 = str(splitline[0])                        \n",
    "                start = int(splitline[1])                                  \n",
    "                chr2 = str(splitline[2])                        \n",
    "                end = int(splitline[3])                                                \n",
    "                sv_type = str(splitline[4])\n",
    "                \n",
    "                #Add 0 as identifier for negative SVs\n",
    "                SVdata.append([chr1, start, chr2, end, sv_type, pathogenic])    \n",
    "        \n",
    "            elif pathogenic == 1:\n",
    "                chr1 = \"chr\" + str(splitline[0])\n",
    "                chr2 = \"chr\" + str(splitline[1])\n",
    "                start = int(splitline[2])       \n",
    "                end = int(splitline[3])\n",
    "                sv_type = str(splitline[4])\n",
    "                \n",
    "                #Add 1 as identifier for positive SVs\n",
    "                SVdata.append([chr1, start, chr2, end, sv_type, pathogenic])\n",
    "    \n",
    "    SVdata = np.array(SVdata, dtype = \"object\")                     \n",
    "    return SVdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to annotate the SVs using Giggle. Translocations are annotated at the breakpoints only in a small surrounding window while duplications and deletions are \n",
    "annotated along their entire interval. The annotations are: length, overlapping tads, overlapping genes, gene names, pli scores, number of pli scores > 0.9, rvis scores,\n",
    "number of rvis scores < 10, chromatin state at breakpoint 1, chromatin state at breakpoint 2. \n",
    "'''\n",
    "def annotate(data, index):\n",
    "    start_time = time.time()\n",
    "    breakpoint_window = 100 #Window for determining the overlapping TADs and genes at breakpoints for translocations only, not deletions and duplications\n",
    "    annotated_SVs = []\n",
    "    \n",
    "    for sv in data:\n",
    "        #Make new list to append annotations to\n",
    "        current_sv = [sv[0], sv[1], sv[2], sv[3], sv[4], sv[5]]\n",
    "        genes = \"\"\n",
    "        pli_scores = \"\"\n",
    "        pli_count = 0\n",
    "        rvis_scores = \"\"\n",
    "        rvis_count = 0\n",
    "        total_num_HPO_terms = 0\n",
    "        \n",
    "        #DELETIONS AND DUPLICATIONS\n",
    "        if current_sv[4] == \"Duplication\" or current_sv[4] == \"Deletion\" or current_sv[4] == \"DUP\" or current_sv[4] == \"DEL\": \n",
    "        \n",
    "            #take into account that it is possible that some start and end position are reversed and Giggle cant search this\n",
    "            if sv[1] <= sv[3]: \n",
    "                sv_length = sv[3] - sv[1]\n",
    "                #search the enitre index using the current chromosome, start position and end position\n",
    "                result = index.query(current_sv[0], current_sv[1], current_sv[3])\n",
    "            \n",
    "            elif sv[1] > sv[3]:\n",
    "                sv_length = sv[1] - sv[3]\n",
    "                #search the enitre index using the current chromosome, start position and end position\n",
    "                result = index.query(current_sv[0], current_sv[3], current_sv[1])\n",
    "            \n",
    "            #Total number of TADs overlapping with the SV interval\n",
    "            tad_hits = result.n_hits(1) #this returns the number of hits in the second file in the index (TADs)\n",
    "            \n",
    "            #Total number of genes overlapping with the SV interval\n",
    "            gene_hits = result.n_hits(0) #same but for genes\n",
    "            \n",
    "            #Extracting the gene names and scores from the hits. Order of genes names corresponds with order of scores\n",
    "            for hit in result[0]: #Iterating over all gene hits\n",
    "                gene = hit.split()[3] #Extracting the gene name\n",
    "                genes += (gene + \" \") \n",
    "\n",
    "                pli = hit.split()[6] #Extracting the pli score\n",
    "                pli_scores += (pli + \" \")\n",
    "                #If the pli score is larger than 0.9, count it\n",
    "                if pli != \"NA\":\n",
    "                    if float(pli) >= 0.9:\n",
    "                        pli_count += 1\n",
    "                    \n",
    "                rvis = hit.split()[7]\n",
    "                rvis_scores += (rvis + \" \")\n",
    "                if rvis != \"NA\":\n",
    "                    if float(rvis) < 10:\n",
    "                        rvis_count += 1\n",
    "                \n",
    "                #Number of HPO terms associated with the overlapping gene\n",
    "                num_HPO_terms = int(hit.split(\"\\t\")[10])\n",
    "                total_num_HPO_terms += num_HPO_terms\n",
    "            \n",
    "            #if no genes or scores are found to be overlapping, put none as annotation to prevent empty annotations\n",
    "            if len(genes) == 0: \n",
    "                genes += \"\"\n",
    "            if len(pli_scores) == 0:\n",
    "                pli_scores += \"\"\n",
    "            if len(rvis_scores) == 0:\n",
    "                rvis_scores += \"\"\n",
    "            \n",
    "            #Append the annotations to the list of the current SV\n",
    "            current_sv.append(sv_length)\n",
    "            current_sv.append(tad_hits)\n",
    "            current_sv.append(gene_hits)\n",
    "            current_sv.append(genes)\n",
    "            current_sv.append(pli_scores)\n",
    "            current_sv.append(pli_count)\n",
    "            current_sv.append(rvis_scores)\n",
    "            current_sv.append(rvis_count)\n",
    "            current_sv.append(total_num_HPO_terms)\n",
    "            \n",
    "        #TRANSLOCATIONS        \n",
    "        else:\n",
    "            #the length of the SVs is put to zero (translocation have no easy to define lentgh)\n",
    "            sv_length = 0\n",
    "            \n",
    "            #Hits are determined for genes and TADs seperately because they use different windows. Also, both breakpoints are done seperately \n",
    "            result_bp1 = index.query(current_sv[0], current_sv[1] - breakpoint_window, current_sv[1] + breakpoint_window)\n",
    "            #Number of genes overlapping with the window around breakpoint 1\n",
    "            gene_hit_bp1 = result_bp1.n_hits(0)\n",
    "            #Number of TADs overlapping with the window around breakpoint 1\n",
    "            tad_hit_bp1 = result_bp1.n_hits(1)\n",
    "            \n",
    "            #Extracting the gene names and scores from the hits. Order of genes names corresponds with order of scores\n",
    "            for hit in result_bp1[0]:\n",
    "                gene = hit.split()[3]\n",
    "                genes += (gene + \" \")\n",
    "\n",
    "                pli = hit.split()[6]\n",
    "                pli_scores += (pli + \" \")\n",
    "                if pli != \"NA\":\n",
    "                    if float(pli) >= 0.9:\n",
    "                        pli_count += 1\n",
    "                    \n",
    "                rvis = hit.split()[7]\n",
    "                rvis_scores += (rvis + \" \")\n",
    "                if rvis != \"NA\":\n",
    "                    if float(rvis) < 10:\n",
    "                        rvis_count += 1\n",
    "                \n",
    "                num_HPO_terms = int(hit.split(\"\\t\")[10])\n",
    "                total_num_HPO_terms += num_HPO_terms\n",
    "            \n",
    "            #Now the same for breakpoint 2\n",
    "            result_bp2 = index.query(current_sv[0], current_sv[3] - breakpoint_window, current_sv[3] + breakpoint_window)\n",
    "            #Number of genes overlapping with the window around breakpoint 2\n",
    "            gene_hit_bp2 = result_bp2.n_hits(0)\n",
    "            #Number of TADs overlapping with the window around breakpoint 1\n",
    "            tad_hit_bp2 = result_bp2.n_hits(1)\n",
    "            \n",
    "            #Extracting the gene names and scores from the hits. Order of genes names corresponds with order of scores\n",
    "            for hit in result_bp2[0]:\n",
    "                gene = hit.split()[3]\n",
    "                genes += (gene + \" \")\n",
    "\n",
    "                pli = hit.split()[6]\n",
    "                pli_scores += (pli + \" \")\n",
    "                if pli != \"NA\":\n",
    "                    if float(pli) >= 0.9:\n",
    "                        pli_count += 1\n",
    "                \n",
    "                rvis = hit.split()[7]\n",
    "                rvis_scores += (rvis + \" \")\n",
    "                if rvis != \"NA\":\n",
    "                    if float(rvis) < 10:\n",
    "                        rvis_count += 1\n",
    "                \n",
    "                num_HPO_terms = int(hit.split(\"\\t\")[10])\n",
    "                total_num_HPO_terms += num_HPO_terms\n",
    "            \n",
    "            #Append all the annotations to the translocations in the same order as the deletions and duplications\n",
    "            current_sv.append(sv_length)\n",
    "            current_sv.append(tad_hit_bp1 + tad_hit_bp2)\n",
    "            current_sv.append(gene_hit_bp1 + gene_hit_bp2)\n",
    "            current_sv.append(genes)\n",
    "            current_sv.append(pli_scores)\n",
    "            current_sv.append(pli_count)\n",
    "            current_sv.append(rvis_scores)\n",
    "            current_sv.append(rvis_count)\n",
    "            current_sv.append(total_num_HPO_terms)\n",
    "            \n",
    "        #For now, chromatin states are only checked at the exact breakpoint locations to check which functional genomic elements are disrupted. All SV types can therefore be done using the same code\n",
    "        result_bp1 = index.query(current_sv[0], current_sv[1], current_sv[1]) \n",
    "        #There are three SVs that do not have a chromatin state at one of the breakpoints which screws up the np array. For these, just append 0 as a state for now. When categorical features are allowed this can become none\n",
    "        if result_bp1.n_hits(2) == 0:\n",
    "                current_sv.append(0)\n",
    "        else:\n",
    "            for hit in result_bp1[2]:\n",
    "                #current_sv.append(hit.split()[3]) #If you want to append to full chromatin state name instead of only the identifier number\n",
    "                state = hit.split()[3]\n",
    "                current_sv.append(int(state.split(\"_\")[0]))\n",
    "        \n",
    "        result_bp2 = index.query(current_sv[2], current_sv[3], current_sv[3])\n",
    "        if result_bp2.n_hits(2) == 0:\n",
    "                current_sv.append(0)\n",
    "        else:    \n",
    "            for hit in result_bp2[2]:\n",
    "                #current_sv.append(hit.split()[3])\n",
    "                state = hit.split()[3]\n",
    "                current_sv.append(int(state.split(\"_\")[0]))\n",
    "                \n",
    "        #After the SV is completely annotated, append it to a list which will contain all annotated SVs\n",
    "        annotated_SVs.append(current_sv)\n",
    "    \n",
    "    #Convert this list to a numpy array for easier handling\n",
    "    annotated_SVs = np.array(annotated_SVs, dtype=\"object\")\n",
    "    \n",
    "    #Print the time needed for the annotation\n",
    "    print(\"Compute time: %s seconds\" % (time.time() - start_time))\n",
    "    return annotated_SVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = read_sv_data(\"data/TN_127.txt\", 0)\n",
    "tp = read_sv_data(\"data/TP_127.txt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute time: 0.118412017822 seconds\n",
      "Compute time: 0.471872806549 seconds\n"
     ]
    }
   ],
   "source": [
    "annotated_tn = annotate(tn, index)\n",
    "annotated_tp = annotate(tp, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick check to see how these annotations separate the negative SV from the positive SVs\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=5000)\n",
    "tn_tp = np.concatenate((annotated_tn, annotated_tp), axis = 0)\n",
    "tn_tp_features = tn_tp[:,[7,8,11,13,14,15,16]]\n",
    "#Or with the length of the SVs also as feature (much better separation):\n",
    "#tn_tp_features = tn_tp[:,[6,7,8,11,13,14,15,16]]\n",
    "df_tsne_tn_tp = tsne.fit_transform(tn_tp_features)\n",
    "\n",
    "plt.scatter(df_tsne_tn_tp[:,0], df_tsne_tn_tp[:,1], c=tn_tp[:,5])\n",
    "plt.xlabel(\"TSNE1\")\n",
    "plt.ylabel(\"TSNE2\")\n",
    "plt.title(\"TSNE plot for annotated SVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
